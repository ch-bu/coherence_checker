setwd("~/Repositories/coherence_checker/text")
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
library(tidyverse)
library(tm)
library(openNLP)
library(lsa)
library(readability)
tino <- read_csv('orthografie_ korrigiert_final_ausgewertet.csv')
getwd()
tino <- read_csv('orthografie_korrigiert_final_ausgewertet.csv')
getwd()
setwd("~/Repositories/coherence_checker/text")
tino <- read_csv('orthografie_korrigiert_final_ausgewertet.csv')
getwd()
tino
View(tino)
# Extract sentences
into_sentences <- function(string) {
s <- as.String(string)
a1 <- annotate(s, sent_token_annotator)
s[a1]
}
build_term_matrix <- function(sentence_vector) {
corpus <- Corpus(VectorSource(sentence_vector)) %>%
tm_map(tolower) %>%
tm_map(removePunctuation) %>%
tm_map(function(x) removeWords(x, stopwords("de"))) %>%
tm_map(stemDocument, language = "de")
as.matrix(TermDocumentMatrix(corpus, control = list(weighting = function(x) weightTfIdf(x, normalize = FALSE))))
}
calc_local_cohesion <- function(cosine_matrix) {
denominator <- nrow(cosine_matrix) - 1
numerator <- 0
for (i in 1:denominator) {
column <- i
row <- i + 1
numerator <- numerator + cosine_matrix[row, column]
}
numerator / denominator
}
calc_global_cohesion <- function(cosine_matrix) {
denominator <- 0
numerator <- 0
for (column in 1:(nrow(cosine_matrix) - 1)) {
for (row in (column + 1):nrow(cosine_matrix)) {
denominator <- denominator + 1
numerator <- numerator + cosine_matrix[row, column]
}
}
numerator / denominator
}
# Build Sentence tokenizer
sent_token_annotator <- Maxent_Sent_Token_Annotator(language = "de")
# https://stats.stackexchange.com/questions/108156/understanding-singular-value-decomposition-in-the-context-of-lsi
# https://nlp.stanford.edu/IR-book/html/htmledition/latent-semantic-indexing-1.html
# Build matrixes
tino_lsa <- tino %>%
mutate(sentences           = text %>% map(into_sentences),
term_matrix         = sentences %>% map(build_term_matrix),
lsa                 = term_matrix %>% map(~ lsa(., 100)),
textmatrix          = lsa %>% map(~ as.textmatrix(.)),
cosine_matrix       = textmatrix %>% map(cosine),
cosine_matrix_no_na = cosine_matrix %>% map(~ replace(., is.nan(.), 0)),
dimensions          = textmatrix %>% map(nrow),
lsa_local           = unlist(cosine_matrix_no_na %>% map(calc_local_cohesion)),
lsa_global          = unlist(cosine_matrix_no_na %>% map(calc_global_cohesion)))
glimpse(tion)
glimpse(tino)
# Build matrixes
tino_lsa <- tino %>%
mutate(sentences           = text %>% map(into_sentences),
term_matrix         = sentences %>% map(build_term_matrix))
# Build matrixes
tino_lsa <- tino %>%
mutate(sentences           = text %>% map(into_sentences))
tino_lsa
View(tino_lsa)
# Build matrixes
tino_lsa <- tino %>%
mutate(sentences           = text %>% map(into_sentences),
term_matrix         = sentences %>% map(build_term_matrix))
hist(tino$num_sentences)
tino <- read_csv('orthografie_korrigiert_final_ausgewertet.csv') %>%
filter(sentences > 1)
setwd("~/Repositories/coherence_checker/text")
tino <- read_csv('orthografie_korrigiert_final_ausgewertet.csv') %>%
filter(sentences > 1)
setwd("~/Repositories/coherence_checker/text")
tino <- read_csv('orthografie_korrigiert_final_ausgewertet.csv') %>%
filter(sentences > 1)
tino <- read_csv('orthografie_korrigiert_final_ausgewertet.csv') %>%
filter(num_sentences > 1)
setwd("~/Repositories/coherence_checker/text")
tino <- read_csv('orthografie_korrigiert_final_ausgewertet.csv') %>%
filter(num_sentences > 1)
getwd()
# Build matrixes
tino_lsa <- tino %>%
mutate(sentences           = text %>% map(into_sentences),
term_matrix         = sentences %>% map(build_term_matrix))
# Build matrixes
tino_lsa <- tino %>%
mutate(sentences           = text %>% map(into_sentences),
term_matrix         = sentences %>% map(build_term_matrix),
lsa                 = term_matrix %>% map(~ lsa(., 100)),
textmatrix          = lsa %>% map(~ as.textmatrix(.)),
cosine_matrix       = textmatrix %>% map(cosine),
cosine_matrix_no_na = cosine_matrix %>% map(~ replace(., is.nan(.), 0)),
dimensions          = textmatrix %>% map(nrow),
lsa_local           = unlist(cosine_matrix_no_na %>% map(calc_local_cohesion)),
lsa_global          = unlist(cosine_matrix_no_na %>% map(calc_global_cohesion)))
?lsa
# Build matrixes
tino_lsa <- tino %>%
mutate(sentences           = text %>% map(into_sentences),
term_matrix         = sentences %>% map(build_term_matrix),
lsa                 = term_matrix %>% map(~ lsa(., dims=dimcalc_share())),
textmatrix          = lsa %>% map(~ as.textmatrix(.)),
cosine_matrix       = textmatrix %>% map(cosine),
cosine_matrix_no_na = cosine_matrix %>% map(~ replace(., is.nan(.), 0)),
dimensions          = textmatrix %>% map(nrow),
lsa_local           = unlist(cosine_matrix_no_na %>% map(calc_local_cohesion)),
lsa_global          = unlist(cosine_matrix_no_na %>% map(calc_global_cohesion)))
tino_lsa
# Write data to disk
tino_lsa <- tino_lsa %>%
select(-sentences, -term_matrix, -textmatrix,
-cosine_matrix, -cosine_matrix_no_na, -dimensions, -lsa)
View(tino_lsa)
plot(tino_lsa$local_cohesion, tino_lsa$lsa_local)
# Calculate Flesh-Kincaid
tino_readability <- readability::readability(tino$text, tino$topic)
# Select Flesch_Kincaid readability score
flesh_data <- tino_readability %>%
select(topic, Flesch_Kincaid)
tino_readability
tino
# Calculate Flesh-Kincaid
tino_readability <- readability::readability(tino$text, tino$id)
tino_readability
# Select Flesch_Kincaid readability score
flesh_data <- tino_readability %>%
select(topic, Flesch_Kincaid)
# Select Flesch_Kincaid readability score
flesh_data <- tino_readability %>%
select(id, Flesch_Kincaid)
flesh_data
flesh_data
tino_readability
tino_readability %>% as.data.frame(.)
tino_readability <- tino_readability %>% as.data.frame(.)
tino_readability <- tino_readability %>% as.data.frame(.) %>% select(Flesch_Kincaid)
tino_readability
tino_readability <- tino_readability %>% as.data.frame(.) %>% select(id, Flesch_Kincaid)
tino_readability
# Calculate Flesh-Kincaid
tino_readability <- readability::readability(tino$text, tino$id)
# Calculate Flesh-Kincaid
tino_readability
tino_readability %>% as.data.frame(.)
tino_readability <- tino_readability %>% as.data.frame(.) %>%
select(id, Flesch_Kincaid)
tino_readability
# Merge with existing data frame
tino_lsa_readability<- merge(tino_lsa, flesh_data, by = "topic")
# Merge with existing data frame
tino_lsa_readability<- merge(tino_lsa, flesh_data, by = "id")
tino_lsa_readability
View(tino_lsa_readability)
output <- tino_lsa_readability %>% select(-text)
write_csv(wikipedia_merged, "~/Repositories/coherence_checker/text/orthografie_korrigiert_final_results.csv", append = FALSE)
write_csv(output, "~/Repositories/coherence_checker/text/orthografie_korrigiert_final_results.csv", append = FALSE)
setwd("~/Repositories/coherence_checker/text")
tino <- read_csv('kasus_verbflexion_satzbau_korrigiert_ausgewertet.csv') %>%
filter(num_sentences > 1)
getwd()
# Extract sentences
into_sentences <- function(string) {
s <- as.String(string)
a1 <- annotate(s, sent_token_annotator)
s[a1]
}
build_term_matrix <- function(sentence_vector) {
corpus <- Corpus(VectorSource(sentence_vector)) %>%
tm_map(tolower) %>%
tm_map(removePunctuation) %>%
tm_map(function(x) removeWords(x, stopwords("de"))) %>%
tm_map(stemDocument, language = "de")
as.matrix(TermDocumentMatrix(corpus, control = list(weighting = function(x) weightTfIdf(x, normalize = FALSE))))
}
calc_local_cohesion <- function(cosine_matrix) {
denominator <- nrow(cosine_matrix) - 1
numerator <- 0
for (i in 1:denominator) {
column <- i
row <- i + 1
numerator <- numerator + cosine_matrix[row, column]
}
numerator / denominator
}
calc_global_cohesion <- function(cosine_matrix) {
denominator <- 0
numerator <- 0
for (column in 1:(nrow(cosine_matrix) - 1)) {
for (row in (column + 1):nrow(cosine_matrix)) {
denominator <- denominator + 1
numerator <- numerator + cosine_matrix[row, column]
}
}
numerator / denominator
}
# Build Sentence tokenizer
sent_token_annotator <- Maxent_Sent_Token_Annotator(language = "de")
# https://stats.stackexchange.com/questions/108156/understanding-singular-value-decomposition-in-the-context-of-lsi
# https://nlp.stanford.edu/IR-book/html/htmledition/latent-semantic-indexing-1.html
# Build matrixes
tino_lsa <- tino %>%
mutate(sentences           = text %>% map(into_sentences),
term_matrix         = sentences %>% map(build_term_matrix),
lsa                 = term_matrix %>% map(~ lsa(., dims=dimcalc_share())),
textmatrix          = lsa %>% map(~ as.textmatrix(.)),
cosine_matrix       = textmatrix %>% map(cosine),
cosine_matrix_no_na = cosine_matrix %>% map(~ replace(., is.nan(.), 0)),
dimensions          = textmatrix %>% map(nrow),
lsa_local           = unlist(cosine_matrix_no_na %>% map(calc_local_cohesion)),
lsa_global          = unlist(cosine_matrix_no_na %>% map(calc_global_cohesion)))
# Write data to disk
tino_lsa <- tino_lsa %>%
select(-sentences, -term_matrix, -textmatrix,
-cosine_matrix, -cosine_matrix_no_na, -dimensions, -lsa)
# Calculate Flesh-Kincaid
tino_readability <- readability::readability(tino$text, tino$id)
tino_readability <- tino_readability %>% as.data.frame(.) %>%
select(id, Flesch_Kincaid)
# Select Flesch_Kincaid readability score
flesh_data <- tino_readability %>%
select(id, Flesch_Kincaid)
# Merge with existing data frame
tino_lsa_readability<- merge(tino_lsa, flesh_data, by = "id")
output <- tino_lsa_readability %>% select(-text)
write_csv(output, "~/Repositories/coherence_checker/text/kasus_verbflexion_satzbau_korrigiert_results.csv", append = FALSE)
View(output)
